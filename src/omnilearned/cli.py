import typer
from types import SimpleNamespace
from omnilearned.train import run as run_training
from omnilearned.evaluate import run as run_evaluation
from omnilearned.dataloader import load_data, Task
from omnilearned.train_hl import run as run_training_hl
from omnilearned.evaluate_hl import run as run_evaluation_hl


app = typer.Typer(
    help="OmniLearned: A unified deep learning approach for particle physics",
    no_args_is_help=True,
    pretty_exceptions_show_locals=False,
)


def create_task(args):
    if args.mode == "regression":
        class_label_idx = None
        class_idx = None
        if args.regress_E_available:
            class_label_idx = 8
        elif args.regress_E_available_no_muon:
            class_label_idx = 9
        return Task(type="regression", regress_E_available=args.regress_E_available, regress_E_available_no_muon=args.regress_E_available_no_muon, class_label_idx=class_label_idx)
    elif args.mode == "classifier":
        if "classification_n_pions" not in args.__dict__:
            args.classification_n_pions = False
        if args.classification_event_type:
            class_label_idx = 1
            class_idx = [1, 2, 3, 4, 8]
            class_idx_map = {1: 0, 2: 1, 3: 2, 4: 3, 8: 4}
        elif args.classification_current:
            class_label_idx = 3
            class_idx = [1, 2]
            class_idx_map = {1: 0, 2: 1}
        elif args.classification_cc_1pi:
            class_label_idx = 4
            class_idx = [0, 1, 2]
            class_idx_map = {0: 0, 1: 1, 2: 2}
        elif args.classification_n_pions:
            class_label_idx = 7
            class_idx = [0, 1]
            class_idx_map = {0: 0, 1: 1}
        elif args.classification_CC1orNPi:
            class_label_idx = -1
            class_idx = [0, 1, 2, 3]
            class_idx_map = {0: 0, 1: 1, 2: 2, 3: 3}
        return Task(type="classifier", classification_event_type=args.classification_event_type, 
            classification_current=args.classification_current, classification_cc_1pi=args.classification_cc_1pi,
            classification_n_pions=args.classification_n_pions, class_idx=class_idx, class_idx_map=class_idx_map, class_label_idx=class_label_idx,
            classification_CC1orNPi=args.classification_CC1orNPi)
    else:
        raise ValueError("Invalid mode")


@app.command()
def train(
    # General Options
    outdir: str = typer.Option(
        "", "--output_dir", "-o", help="Directory to output best model"
    ),
    save_tag: str = typer.Option("", help="Extra tag for checkpoint model"),
    pretrain_tag: str = typer.Option(
        "", help="Tag given to pretrained checkpoint model"
    ),
    dataset: str = typer.Option("top", help="Dataset to load"),
    path: str = typer.Option("/pscratch/sd/v/vmikuni/datasets", help="Dataset path"),
    wandb: bool = typer.Option(False, help="use wandb logging"),
    fine_tune: bool = typer.Option(False, help="Fine tune the model"),
    resuming: bool = typer.Option(False, help="Resume training"),
    # Model Options
    num_feat: int = typer.Option(
        4,
        help="Number of input kinematic features (not considering PID or additional features)",
    ),
    size: str = typer.Option("small", "--size", "-s", help="Model size"),
    interaction: bool = typer.Option(False, help="Use interaction matrix"),
    local_interaction: bool = typer.Option(False, help="Use local interaction matrix"),
    num_coord: int = typer.Option(
        2, help="Number of features for distance calculation"
    ),
    K: int = typer.Option(10, help="Number of k-neighbors"),
    interaction_type: str = typer.Option("lhc", help="Type of interaction"),
    conditional: bool = typer.Option(False, help="Use global conditional features"),
    num_cond: int = typer.Option(3, help="Number of global conditioning features"),
    use_pid: bool = typer.Option(False, help="Use particle ID for training"),
    pid_idx: int = typer.Option(4, help="Index of the PID in the input array"),
    pid_dim: int = typer.Option(8, help="Number of unique PIDs"),
    use_add: bool = typer.Option(
        True, help="Use additional features beyond kinematic information"
    ),
    num_add: int = typer.Option(5, help="Number of additional features"),
    zero_add: bool = typer.Option(
        False,
        help="Load the model with additional blocks but zero the inputs from the dataloader",
    ),
    use_clip: bool = typer.Option(False, help="Use CLIP loss during training"),
    use_event_loss: bool = typer.Option(
        False, help="Use additional classification loss between physics process"
    ),
    mode: str = typer.Option(
        "classifier", help="Task to run: classifier, generator, pretrain"
    ),
    regression_loss: str = typer.Option(
        "mse", help="Regression loss type: mse (L2), l1 (MAE), or huber"
    ),
    # Training options
    batch: int = typer.Option(64, help="Batch size"),
    iterations: int = typer.Option(-1, help="Number of iterations per pass"),
    epoch: int = typer.Option(10, help="Number of epochs"),
    warmup_epoch: int = typer.Option(0, help="Number of learning rate warmup epochs"),
    use_amp: bool = typer.Option(False, help="Use amp"),
    clip_inputs: bool = typer.Option(
        False, help="Clip input dataset to be within R=0.8 and atl least 500 MeV"
    ),
    # Optimizer
    optim: str = typer.Option("lion", help="optimizer to use"),
    sched: str = typer.Option("cosine", help="lr scheduler to use"),
    b1: float = typer.Option(0.95, help="Lion b1"),
    b2: float = typer.Option(0.98, help="Lion b2"),
    lr: float = typer.Option(5e-5, help="Learning rate"),
    lr_factor: float = typer.Option(
        1.0, help="Learning rate factor for new layers during fine-tuning"
    ),
    wd: float = typer.Option(0.0, help="Weight decay"),
    nevts: int = typer.Option(-1, help="Maximum number of events to use"),
    # Model
    attn_drop: float = typer.Option(0.0, help="Dropout for attention layers"),
    mlp_drop: float = typer.Option(0.0, help="Dropout for mlp layers"),
    feature_drop: float = typer.Option(0.0, help="Dropout for input features"),
    num_workers: int = typer.Option(16, help="Number of workers for data loading"),
    max_particles: int = typer.Option(150, help="Maximum number of particles per event"),
    class_current_type: bool = typer.Option(False, help="Classify current type"),
    class_pions: bool = typer.Option(False, help="Classify single pion"),
    regress_E_available: bool = typer.Option(False, help="Regress energy available"),
    regress_E_available_no_muon: bool = typer.Option(False, help="Regress energy available without muon"),
):
    args = SimpleNamespace(
        mode=mode,
        regress_log=True,
        regress_E_available=regress_E_available,
        regress_E_available_no_muon=regress_E_available_no_muon,
        classification_event_type=False,
        classification_current=class_current_type,
        classification_cc_1pi=False,
        classification_n_pions=False,
        classification_CC1orNPi=class_pions,
    )
    task = create_task(args)
    num_classes = len(task.class_idx_map) if task.class_idx_map is not None else 2
    run_training(
        outdir,
        save_tag,
        pretrain_tag,
        dataset,
        path,
        wandb,
        fine_tune,
        resuming,
        num_feat,
        size,
        interaction,
        local_interaction,
        num_coord,
        K,
        interaction_type,
        conditional,
        num_cond,
        use_pid,
        pid_idx,
        pid_dim,
        use_add,
        num_add,
        zero_add,
        use_clip,
        use_event_loss,
        num_classes,
        2,
        mode,
        batch,
        iterations,
        epoch,
        warmup_epoch,
        use_amp,
        optim,
        sched,
        b1,
        b2,
        lr,
        lr_factor,
        wd,
        nevts,
        attn_drop,
        mlp_drop,
        feature_drop,
        num_workers,
        clip_inputs=clip_inputs,
        regression_loss=regression_loss,
        regress_log=True,
        max_particles=max_particles,
        task=task
    )


@app.command()
def train_hl(
    # General Options
    outdir: str = typer.Option(
        "", "--output_dir", "-o", help="Directory to output best model"
    ),
    save_tag: str = typer.Option("", help="Extra tag for checkpoint model"),
    dataset: str = typer.Option("top", help="Dataset to load"),
    path: str = typer.Option("/pscratch/sd/v/vmikuni/datasets", help="Dataset path"),
    wandb: bool = typer.Option(False, help="use wandb logging"),
    resuming: bool = typer.Option(False, help="Resume training"),
    # Model Options
    num_feat: int = typer.Option(
        3,
        help="Number of input kinematic features (not considering PID or additional features)",
    ),
    conditional: bool = typer.Option(False, help="Use global conditional features"),
    num_cond: int = typer.Option(1, help="Number of global conditioning features"),
    # Training options
    batch: int = typer.Option(64, help="Batch size"),
    iterations: int = typer.Option(-1, help="Number of iterations per pass"),
    epoch: int = typer.Option(10, help="Number of epochs"),
    warmup_epoch: int = typer.Option(0, help="Number of learning rate warmup epochs"),
    # Optimizer
    optim: str = typer.Option("lion", help="optimizer to use"),
    b1: float = typer.Option(0.95, help="Lion b1"),
    b2: float = typer.Option(0.98, help="Lion b2"),
    lr: float = typer.Option(5e-5, help="Learning rate"),
    wd: float = typer.Option(0.0, help="Weight decay"),
    # Model
    mlp_drop: float = typer.Option(0.0, help="Dropout for mlp layers"),
    num_workers: int = typer.Option(16, help="Number of workers for data loading"),
):
    run_training_hl(
        outdir,
        save_tag,
        dataset,
        path,
        wandb,
        resuming,
        num_feat,
        conditional,
        num_cond,
        batch,
        iterations,
        epoch,
        warmup_epoch,
        optim,
        b1,
        b2,
        lr,
        wd,
        mlp_drop,
    )


@app.command()
def evaluate(
    # General Options
    indir: str = typer.Option(
        "", "--input_dir", "-i", help="Directory to input best model"
    ),
    outdir: str = typer.Option(
        "", "--output_dir", "-o", help="Directory to output evaluation results"
    ),
    save_tag: str = typer.Option("", help="Extra tag for checkpoint model"),
    dataset: str = typer.Option("top", help="Dataset to load"),
    path: str = typer.Option("/pscratch/sd/v/vmikuni/datasets", help="Dataset path"),
    # Model Options
    num_feat: int = typer.Option(
        4,
        help="Number of input kinematic features (not considering PID or additional features)",
    ),
    size: str = typer.Option("small", "--size", "-s", help="Model size"),
    interaction: bool = typer.Option(False, help="Use interaction matrix"),
    local_interaction: bool = typer.Option(False, help="Use local interaction matrix"),
    num_coord: int = typer.Option(
        2, help="Number of features for distance calculation"
    ),
    K: int = typer.Option(10, help="Number of k-neighbors"),
    interaction_type: str = typer.Option("lhc", help="Type of interaction"),
    conditional: bool = typer.Option(False, help="Use global conditional features"),
    num_cond: int = typer.Option(3, help="Number of global conditioning features"),
    use_pid: bool = typer.Option(False, help="Use particle ID for training"),
    pid_idx: int = typer.Option(4, help="Index of the PID in the input array"),
    use_add: bool = typer.Option(
        False, help="Use additional features beyond kinematic information"
    ),
    num_add: int = typer.Option(5, help="Number of additional features"),
    use_event_loss: bool = typer.Option(
        False, help="Use additional classification loss between physics process"
    ),
    num_classes: int = typer.Option(
        2, help="Number of classes in the classification task"
    ),
    num_gen_classes: int = typer.Option(
        1, help="Number of classes in the particle segmentation task"
    ),
    mode: str = typer.Option(
        "classifier", help="Task to run: classifier, generator, pretrain"
    ),
    # Training options
    batch: int = typer.Option(128, help="Batch size"),
    clip_inputs: bool = typer.Option(
        False, help="Clip input dataset to be within R=0.8 and atl least 500 MeV"
    ),
    num_workers: int = typer.Option(16, help="Number of workers for data loading"),
    max_particles: int = typer.Option(33, help="Maximum number of particles per event"),
    class_event_type: bool = typer.Option(False, help="Classify event type"),
    class_current_type: bool = typer.Option(False, help="Classify current type"),
):
    num_classes = len(task.class_idx_map) if task.class_idx_map is not None else 2
    run_evaluation(
        indir,
        outdir,
        save_tag,
        dataset,
        path,
        num_feat,
        size,
        interaction,
        local_interaction,
        num_coord,
        K,
        interaction_type,
        conditional,
        num_cond,
        use_pid,
        pid_idx,
        use_add,
        num_add,
        use_event_loss,
        num_classes,
        num_gen_classes,
        mode,
        batch,
        num_workers,
        clip_inputs=clip_inputs,
        max_particles=max_particles,
        class_event_type=class_event_type,
        class_current_type=class_current_type,
    )


@app.command()
def evaluate_hl(
    # General Options
    indir: str = typer.Option(
        "", "--input_dir", "-i", help="Directory to input best model"
    ),
    outdir: str = typer.Option("", "--output_dir", "-o", help="Output saved files"),
    save_tag: str = typer.Option("", help="Extra tag for checkpoint model"),
    dataset: str = typer.Option("top", help="Dataset to load"),
    path: str = typer.Option("/pscratch/sd/v/vmikuni/datasets", help="Dataset path"),
    # Model Options
    num_feat: int = typer.Option(
        3,
        help="Number of input kinematic features (not considering PID or additional features)",
    ),
    conditional: bool = typer.Option(False, help="Use global conditional features"),
    num_cond: int = typer.Option(3, help="Number of global conditioning features"),
    # Training options
    batch: int = typer.Option(128, help="Batch size"),
    num_workers: int = typer.Option(16, help="Number of workers for data loading"),
):
    run_evaluation_hl(
        indir,
        outdir,
        save_tag,
        dataset,
        path,
        num_feat,
        conditional,
        num_cond,
        batch,
        num_workers,
    )


@app.command()
def dataloader(
    dataset: str = typer.Option(
        "top", "--dataset", "-d", help="Dataset name to download"
    ),
    folder: str = typer.Option(
        "./", "--folder", "-f", help="Folder to save the dataset"
    ),
):
    for tag in ["train", "test", "val"]:
        print(tag)
        load_data(dataset, folder, dataset_type=tag, distributed=False)


if __name__ == "__main__":
    app()
